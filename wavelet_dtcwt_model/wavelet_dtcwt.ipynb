{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPa0i9qT38Mq"
      },
      "source": [
        "### Try to load the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_73TAZk38Mt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "SETS = ['training', 'validation', 'tests']\n",
        "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV9Zo_bT38Mu"
      },
      "outputs": [],
      "source": [
        "# https://scikit-learn.org/stable/model_persistence.html\n",
        "try:\n",
        "    dtcwt_rf = pickle.load('dtcwt/dtcwt_rf.bin','rb')\n",
        "    loaded_model = True\n",
        "except:\n",
        "    loaded_model = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYQk9IE938Mu"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvdQjsEW38Mu"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import scipy\n",
        "import dtcwt\n",
        "\n",
        "trans = dtcwt.Transform1d(biort='antonini', qshift='qshift_d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bMt-gay38Mu"
      },
      "outputs": [],
      "source": [
        "def calculate_entropy(list_values):\n",
        "\tcounter_values = Counter(list_values).most_common()\n",
        "\tprobabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
        "\tentropy=scipy.stats.entropy(probabilities)\n",
        "\treturn entropy\n",
        "\n",
        "def calculate_statistics(list_values):\n",
        "\tn5 = np.nanpercentile(list_values, 5)\n",
        "\tn25 = np.nanpercentile(list_values, 25)\n",
        "\tn75 = np.nanpercentile(list_values, 75)\n",
        "\tn95 = np.nanpercentile(list_values, 95)\n",
        "\tmedian = np.nanpercentile(list_values, 50)\n",
        "\tmean = np.nanmean(list_values)\n",
        "\tstd = np.nanstd(list_values)\n",
        "\tvar = np.nanvar(list_values)\n",
        "\trms = np.nanmean(np.sqrt(list_values**2))\n",
        "\treturn [n5, n25, n75, n95, median, mean, std, var, rms]\n",
        "\n",
        "def calculate_crossings(list_values):\n",
        "\tzero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
        "\tno_zero_crossings = len(zero_crossing_indices)\n",
        "\tmean_crossing_indices = np.nonzero(np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
        "\tno_mean_crossings = len(mean_crossing_indices)\n",
        "\treturn [no_zero_crossings, no_mean_crossings]\n",
        "\n",
        "def get_features(list_values):\n",
        "\tentropy = calculate_entropy(list_values)\n",
        "\tcrossings = calculate_crossings(list_values)\n",
        "\tstatistics = calculate_statistics(list_values)\n",
        "\treturn [entropy] + crossings + statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ci6GgZF38Mv"
      },
      "source": [
        "## Given an audio file returns the corresponding wavelet features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Vtf7XXP38Mv"
      },
      "outputs": [],
      "source": [
        "def extract_dtcwt(file_path:str):\n",
        "    d, fs = librosa.load(file_path)\n",
        "    forw = trans.forward(d, nlevels=17)\n",
        "    features = []\n",
        "    for coeff in forw.highpasses:\n",
        "        temp = (np.abs(coeff.squeeze()))\n",
        "        features += get_features(temp)\n",
        "\n",
        "    features += get_features(forw.lowpass.squeeze())\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcbsiVBf38Mv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "data_path = 'url'\n",
        "\n",
        "genres = ['blues', 'classical', 'country', 'disco',\n",
        "          'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "def index_genre(genre, genres):\n",
        "    for (g,index) in zip(genres, range(len(genres))):\n",
        "        if(g == genre):\n",
        "            return index\n",
        "    return -1\n",
        "\n",
        "def get_data(data_path, genres, decoder, training_percentaje=0.6, validation_percentaje=0.2, test_percentaje=0.2):\n",
        "    \"\"\"\n",
        "    data_path: se le pasa la direccion de la carpeta donde se encuentra la base de datos.\n",
        "    genres: se le pasa una lista con los nombres da cada carpeta que contiene un genero dado.\n",
        "    decoder: funcion para decodificar el dato que se le pasa, por ejemplo en caso de imagenes habria hacer imread\n",
        "    \"\"\"\n",
        "\n",
        "    data_training = {'in': [], 'out': []}\n",
        "    data_validation = {'in': [], 'out': []}\n",
        "    data_test = {'in': [], 'out': []}\n",
        "\n",
        "    for genre in genres:\n",
        "        files = os.listdir(data_path + genre)\n",
        "        count = len(files)\n",
        "\n",
        "        for (filename, index) in zip(files, range(len(files))):\n",
        "            filepath = data_path + genre + '/' + filename\n",
        "\n",
        "            if (index < training_percentaje * count):\n",
        "                data_training['in'].append(decoder(filepath))\n",
        "                data_training['out'].append(index_genre(genre, genres))\n",
        "                continue\n",
        "\n",
        "            if (index < (training_percentaje + validation_percentaje) * count):\n",
        "                data_validation['in'].append(decoder(filepath))\n",
        "                data_validation['out'].append(index_genre(genre, genres))\n",
        "            else:\n",
        "                data_test['in'].append(decoder(filepath))\n",
        "                data_test['out'].append(index_genre(genre, genres))\n",
        "\n",
        "    data_training = {'in': np.array(data_training['in']),'out': np.array(data_training['out'])}\n",
        "    data_validation = {'in': np.array(data_validation['in']),'out': np.array(data_validation['out'])}\n",
        "    data_test = {'in': np.array(data_test['in']),'out': np.array(data_test['out'])}\n",
        "\n",
        "    return {\n",
        "        'data_training': data_training,\n",
        "        'data_validation': data_validation,\n",
        "        'data_testing': data_test\n",
        "    }\n",
        "\n",
        "def get_data_wavelet(training_percentaje=0.8, validation_percentaje=0.1, test_percentaje=0.1):\n",
        "    return get_data(data_path, genres, extract_dtcwt, training_percentaje,validation_percentaje,test_percentaje)\n",
        "\n",
        "wavalet_data = get_data_wavelet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWncKx5d38Mw"
      },
      "source": [
        "### If you want the features for the whole dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYDJ9NyQ38Mx"
      },
      "outputs": [],
      "source": [
        "x_features = []\n",
        "y  = []\n",
        "for genre in GENRES:\n",
        "    for wav in os.listdir(f'dataset/genres/{genre}'):\n",
        "        matched = re.match(r\"(\\w+).(\\d+).wav\", wav)\n",
        "        if matched:\n",
        "            features = extract_dtcwt(f'dataset/genres/{genre}/{wav}')\n",
        "\n",
        "            y.append(genre)\n",
        "            x_features.append(features)\n",
        "\n",
        "x_features = np.array(x_features)\n",
        "y = np.array(y)\n",
        "np.save('dtcwt/dtcwt_15_lvl17', x_features)\n",
        "np.save('dtcwt/dtcwt_y', y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1k3sZZ38My"
      },
      "outputs": [],
      "source": [
        "X_dtcwt = np.load('dtcwt/dtcwt_15_lvl17.npy')\n",
        "y = np.load('dtcwt/dtcwt_y.npy')\n",
        "X_dtcwt.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmvfAg1t38My"
      },
      "source": [
        "Get a random scaled, train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSiIlVXC38My"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "def encoder_scaler(X_dtcwt, y):\n",
        "    encoder = LabelEncoder()\n",
        "    y = encoder.fit_transform(y)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_dtcwt_scaled = scaler.fit_transform(X_dtcwt)\n",
        "    X_dtcwt_train_f, X_dtcwt_test_f, y_dtcwt_train_f, y_dtcwt_test_f = train_test_split(X_dtcwt_scaled, y, test_size = 0.2,random_state=42)\n",
        "    return X_dtcwt_train_f, X_dtcwt_test_f, y_dtcwt_train_f, y_dtcwt_test_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yfsaYAB38My"
      },
      "outputs": [],
      "source": [
        "X_dtcwt = np.load('dtcwt/dtcwt_15_lvl17.npy')\n",
        "y = np.load('dtcwt/dtcwt_y.npy')\n",
        "# retrain model\n",
        "# X_dtcwt_train_f, X_dtcwt_test_f, y_dtcwt_train_f, y_dtcwt_test_f = encoder_scaler(X_dtcwt, y)\n",
        "\n",
        "dtcwt_rf = RandomForestClassifier(n_estimators=100,max_depth=13,bootstrap=False,random_state=42)\n",
        "\n",
        "#region new changes\n",
        "X_dtcwt_train_f = wavalet_data['data_training']['in']\n",
        "y_dtcwt_train_f = wavalet_data['data_training']['out']\n",
        "X_dtcwt_test_f =  wavalet_data['data_testing']['in']\n",
        "y_dtcwt_test_f =  wavalet_data['data_testing']['out']\n",
        "#endregion\n",
        "\n",
        "dtcwt_rf.fit(X_dtcwt_train_f,y_dtcwt_train_f)\n",
        "\n",
        "with open('dtcwt/dtcwt_rf.bin','wb') as mod:\n",
        "    pickle.dump(dtcwt_rf,mod)\n",
        "# https://scikit-learn.org/stable/model_persistence.html\n",
        "\n",
        "print(dtcwt_rf.score(X_dtcwt_test_f, y_dtcwt_test_f))\n",
        "ypred_dtcwt_rf = dtcwt_rf.predict(X_dtcwt_test_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS34kt0Y38Mz"
      },
      "source": [
        "Plot a confusion matrix to corroborate the behavior of the model for each genre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0S5kV8j38Mz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# create confusion matrix\n",
        "cm = confusion_matrix(y_dtcwt_test_f, ypred_dtcwt_rf)\n",
        "\n",
        "accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "misclass = 1 - accuracy\n",
        "\n",
        "cmap = plt.get_cmap('Blues')\n",
        "\n",
        "# plot confusion matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "plt.title('Confusion matrix DTCWT Random Forest')\n",
        "plt.colorbar()\n",
        "\n",
        "tick_marks = np.arange(len(GENRES))\n",
        "plt.xticks(tick_marks, GENRES, rotation=45)\n",
        "plt.yticks(tick_marks, GENRES)\n",
        "\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > (cm.max() / 2) else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "plt.savefig('ConfM_DTCWT_rf.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orGMA68s38Mz"
      },
      "source": [
        "A Cross-Validation using K-Fold to validate the accuracy in the previous fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGBFdrYW38Mz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "kfold=KFold(n_splits=5 , shuffle=True,random_state=0)\n",
        "rf_scores = cross_val_score(dtcwt_rf, X_dtcwt, y, cv=kfold)\n",
        "\n",
        "print('scores: ',rf_scores) # [0.735      0.705      0.8        0.81       0.79396985]\n",
        "print('mean: ',rf_scores.mean()) # 0.7687939698492463\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Cross-Validation Scores in Random Forest for DTCWT')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Score')\n",
        "ax = plt.gca()\n",
        "ax.set_xlim(0.9, 5.1)\n",
        "ax.set_ylim(0.6, 1.01)\n",
        "plt.grid()\n",
        "plt.plot(range(1,6),rf_scores,'o-',color='blue',lw=2)\n",
        "plt.plot(range(1,6),[rf_scores.mean()]*5, linestyle=\"-.\",color='k')\n",
        "plt.annotate(\"%0.4f\" % rf_scores.mean(), (3,rf_scores.mean() + 0.005))\n",
        "plt.legend(['accuracy','mean acc'],loc=\"best\")\n",
        "plt.savefig('CV_DTCWT_rf.png')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}