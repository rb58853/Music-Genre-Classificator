{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5DcFAwa6Q4A",
        "outputId": "f7444a21-063d-4021-fd93-0e844d53afab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "/usr/bin/xdg-open: 869: www-browser: not found\n",
            "/usr/bin/xdg-open: 869: links2: not found\n",
            "/usr/bin/xdg-open: 869: elinks: not found\n",
            "/usr/bin/xdg-open: 869: links: not found\n",
            "/usr/bin/xdg-open: 869: lynx: not found\n",
            "/usr/bin/xdg-open: 869: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=OtBhzo74rWI51lmIqlnFf74AbSH4j3t8Thsh15MrJGc'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=OtBhzo74rWI51lmIqlnFf74AbSH4j3t8Thsh15MrJGc\")\n"
          ]
        }
      ],
      "source": [
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eWt--1B6Uxp",
        "outputId": "7f4a3895-9cd9-4938-8cff-5dbde9be7fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package w3m.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 123074 files and directories currently installed.)\n",
            "Preparing to unpack .../w3m_0.5.3-37ubuntu0.1_amd64.deb ...\n",
            "Unpacking w3m (0.5.3-37ubuntu0.1) ...\n",
            "Setting up w3m (0.5.3-37ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmGuq6wCSrqq",
        "outputId": "fbc08a7e-5785-488d-c36b-97f01255ad46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dtcwt\n",
            "  Downloading dtcwt-0.12.0.tar.gz (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dtcwt) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from dtcwt) (1.16.0)\n",
            "Building wheels for collected packages: dtcwt\n",
            "  Building wheel for dtcwt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dtcwt: filename=dtcwt-0.12.0-py3-none-any.whl size=87869 sha256=4d3d934ffdc1634bae6b8e8058238872d20f4697a0e011134f6763081a5970ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/50/50/cf98b0e08812889d0f5789d271acbdab7ac7c3086c323a8e0a\n",
            "Successfully built dtcwt\n",
            "Installing collected packages: dtcwt\n",
            "Successfully installed dtcwt-0.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install dtcwt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PPa0i9qT38Mq"
      },
      "source": [
        "### Try to load the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n_73TAZk38Mt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "SETS = ['training', 'validation', 'tests']\n",
        "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AYQk9IE938Mu"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vvdQjsEW38Mu"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import scipy\n",
        "import dtcwt\n",
        "\n",
        "trans = dtcwt.Transform1d(biort='antonini', qshift='qshift_d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-bMt-gay38Mu"
      },
      "outputs": [],
      "source": [
        "def calculate_entropy(list_values):\n",
        "\tcounter_values = Counter(list_values).most_common()\n",
        "\tprobabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
        "\tentropy=scipy.stats.entropy(probabilities)\n",
        "\treturn entropy\n",
        "\n",
        "def calculate_statistics(list_values):\n",
        "\tn5 = np.nanpercentile(list_values, 5)\n",
        "\tn25 = np.nanpercentile(list_values, 25)\n",
        "\tn75 = np.nanpercentile(list_values, 75)\n",
        "\tn95 = np.nanpercentile(list_values, 95)\n",
        "\tmedian = np.nanpercentile(list_values, 50)\n",
        "\tmean = np.nanmean(list_values)\n",
        "\tstd = np.nanstd(list_values)\n",
        "\tvar = np.nanvar(list_values)\n",
        "\trms = np.nanmean(np.sqrt(list_values**2))\n",
        "\treturn [n5, n25, n75, n95, median, mean, std, var, rms]\n",
        "\n",
        "def calculate_crossings(list_values):\n",
        "\tzero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
        "\tno_zero_crossings = len(zero_crossing_indices)\n",
        "\tmean_crossing_indices = np.nonzero(np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
        "\tno_mean_crossings = len(mean_crossing_indices)\n",
        "\treturn [no_zero_crossings, no_mean_crossings]\n",
        "\n",
        "def get_features(list_values):\n",
        "\tentropy = calculate_entropy(list_values)\n",
        "\tcrossings = calculate_crossings(list_values)\n",
        "\tstatistics = calculate_statistics(list_values)\n",
        "\treturn [entropy] + crossings + statistics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ci6GgZF38Mv"
      },
      "source": [
        "## Given an audio file returns the corresponding wavelet features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4Vtf7XXP38Mv"
      },
      "outputs": [],
      "source": [
        "def extract_dtcwt(file_path:str):\n",
        "    d, fs = librosa.load(file_path)\n",
        "    forw = trans.forward(d, nlevels=17)\n",
        "    features = []\n",
        "    for coeff in forw.highpasses:\n",
        "        temp = (np.abs(coeff.squeeze()))\n",
        "        features += get_features(temp)\n",
        "\n",
        "    features += get_features(forw.lowpass.squeeze())\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DcbsiVBf38Mv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "def index_genre(genre, genres):\n",
        "    for (g,index) in zip(genres, range(len(genres))):\n",
        "        if(g == genre):\n",
        "            return index\n",
        "    raise Exception(f\"Not found the {genre}\")\n",
        "\n",
        "def get_data_from_path(data_path,genres, decoder):\n",
        "    data = {'in': [], 'out': []}\n",
        "    for genre in genres:\n",
        "        files = os.listdir(data_path + genre)\n",
        "        for filename in files:\n",
        "            filepath = data_path + genre + '/' + filename\n",
        "            data['in'].append(decoder(filepath))\n",
        "            data['out'].append(index_genre(genre, genres))\n",
        "\n",
        "    data = {'in': np.array(data['in']),'out': np.array(data['out'])}\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path_train = '/content/drive/MyDrive/GTZAN/Ensemble_Data/audios/models/'\n",
        "data_path_test = '/content/drive/MyDrive/GTZAN/Ensemble_Data/audios/models/'\n",
        "data_path_validation = '/content/drive/MyDrive/GTZAN/Ensemble_Data/audios/models/'\n",
        "\n",
        "\n",
        "def get_data_train_wavelet():\n",
        "    return get_data_from_path(data_path_train, genres, extract_dtcwt)\n",
        "def get_data_test_wavelet():\n",
        "    return get_data_from_path(data_path_test, genres, extract_dtcwt)\n",
        "def get_data_validation_wavelet():\n",
        "    return get_data_from_path(data_path_test, genres, extract_dtcwt)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LmvfAg1t38My"
      },
      "source": [
        "Get a random scaled, train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oSiIlVXC38My"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "def encoder_scaler(X_dtcwt, y):\n",
        "    encoder = LabelEncoder()\n",
        "    y = encoder.fit_transform(y)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_dtcwt_scaled = scaler.fit_transform(X_dtcwt)\n",
        "    X_dtcwt_train_f, X_dtcwt_test_f, y_dtcwt_train_f, y_dtcwt_test_f = train_test_split(X_dtcwt_scaled, y, test_size = 0.2,random_state=42)\n",
        "    return X_dtcwt_train_f, X_dtcwt_test_f, y_dtcwt_train_f, y_dtcwt_test_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yfsaYAB38My",
        "outputId": "52033455-0b38-420b-abc9-a8c6cbaae0a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6974789915966386\n"
          ]
        }
      ],
      "source": [
        "dtcwt_rf = RandomForestClassifier(n_estimators=100,max_depth=13,bootstrap=False,random_state=42)\n",
        "\n",
        "data_train = get_data_train_wavelet()\n",
        "data_test = get_data_test_wavelet()\n",
        "X_dtcwt_train_f = data_train ['in']\n",
        "y_dtcwt_train_f = data_train ['out']\n",
        "X_dtcwt_test_f =  data_test['in']\n",
        "y_dtcwt_test_f =  data_test['out']\n",
        "\n",
        "dtcwt_rf.fit(X_dtcwt_train_f,y_dtcwt_train_f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Ensemble/dtcwt_rf.bin','wb') as mod:\n",
        "    pickle.dump(dtcwt_rf,mod)\n",
        "# https://scikit-learn.org/stable/model_persistence.html\n",
        "\n",
        "print(dtcwt_rf.score(X_dtcwt_test_f, y_dtcwt_test_f))\n",
        "ypred_dtcwt_rf = dtcwt_rf.predict(X_dtcwt_test_f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sS34kt0Y38Mz"
      },
      "source": [
        "Plot a confusion matrix to corroborate the behavior of the model for each genre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0S5kV8j38Mz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# create confusion matrix\n",
        "cm = confusion_matrix(y_dtcwt_test_f, ypred_dtcwt_rf)\n",
        "\n",
        "accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "misclass = 1 - accuracy\n",
        "\n",
        "cmap = plt.get_cmap('Blues')\n",
        "\n",
        "# plot confusion matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "plt.title('Confusion matrix DTCWT Random Forest')\n",
        "plt.colorbar()\n",
        "\n",
        "tick_marks = np.arange(len(GENRES))\n",
        "plt.xticks(tick_marks, GENRES, rotation=45)\n",
        "plt.yticks(tick_marks, GENRES)\n",
        "\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > (cm.max() / 2) else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "plt.savefig('ConfM_DTCWT_rf.png')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "orGMA68s38Mz"
      },
      "source": [
        "A Cross-Validation using K-Fold to validate the accuracy in the previous fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGBFdrYW38Mz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "kfold=KFold(n_splits=5 , shuffle=True,random_state=0)\n",
        "rf_scores = cross_val_score(dtcwt_rf, X_dtcwt, y, cv=kfold)\n",
        "\n",
        "print('scores: ',rf_scores) # [0.735      0.705      0.8        0.81       0.79396985]\n",
        "print('mean: ',rf_scores.mean()) # 0.7687939698492463\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Cross-Validation Scores in Random Forest for DTCWT')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Score')\n",
        "ax = plt.gca()\n",
        "ax.set_xlim(0.9, 5.1)\n",
        "ax.set_ylim(0.6, 1.01)\n",
        "plt.grid()\n",
        "plt.plot(range(1,6),rf_scores,'o-',color='blue',lw=2)\n",
        "plt.plot(range(1,6),[rf_scores.mean()]*5, linestyle=\"-.\",color='k')\n",
        "plt.annotate(\"%0.4f\" % rf_scores.mean(), (3,rf_scores.mean() + 0.005))\n",
        "plt.legend(['accuracy','mean acc'],loc=\"best\")\n",
        "plt.savefig('CV_DTCWT_rf.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
