{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ],
      "metadata": {
        "id": "x5DcFAwa6Q4A",
        "outputId": "c6896700-bcb1-44f0-93b4-1d4f462551d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "/usr/bin/xdg-open: 869: www-browser: not found\n",
            "/usr/bin/xdg-open: 869: links2: not found\n",
            "/usr/bin/xdg-open: 869: elinks: not found\n",
            "/usr/bin/xdg-open: 869: links: not found\n",
            "/usr/bin/xdg-open: 869: lynx: not found\n",
            "/usr/bin/xdg-open: 869: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=Lq39QqR571KhkIes8C3blb0KHsZRkGRdtXDfFSyCVuM'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=Lq39QqR571KhkIes8C3blb0KHsZRkGRdtXDfFSyCVuM\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "3eWt--1B6Uxp",
        "outputId": "82e86ab3-ccec-4069-c312-0b1682b0e89b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package w3m.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 123074 files and directories currently installed.)\n",
            "Preparing to unpack .../w3m_0.5.3-37ubuntu0.1_amd64.deb ...\n",
            "Unpacking w3m (0.5.3-37ubuntu0.1) ...\n",
            "Setting up w3m (0.5.3-37ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dtcwt"
      ],
      "metadata": {
        "id": "gmGuq6wCSrqq",
        "outputId": "57eb9021-cd49-41b3-9a46-3859ad54c28f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dtcwt\n",
            "  Downloading dtcwt-0.12.0.tar.gz (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dtcwt) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from dtcwt) (1.16.0)\n",
            "Building wheels for collected packages: dtcwt\n",
            "  Building wheel for dtcwt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dtcwt: filename=dtcwt-0.12.0-py3-none-any.whl size=87869 sha256=02c0d3a9eedbfbf5adf1d2c06526db381d14d493ee169f1649f08fef38ef0748\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/50/50/cf98b0e08812889d0f5789d271acbdab7ac7c3086c323a8e0a\n",
            "Successfully built dtcwt\n",
            "Installing collected packages: dtcwt\n",
            "Successfully installed dtcwt-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPa0i9qT38Mq"
      },
      "source": [
        "### Try to load the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n_73TAZk38Mt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "SETS = ['training', 'validation', 'tests']\n",
        "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYQk9IE938Mu"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vvdQjsEW38Mu"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import scipy\n",
        "import dtcwt\n",
        "\n",
        "trans = dtcwt.Transform1d(biort='antonini', qshift='qshift_d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-bMt-gay38Mu"
      },
      "outputs": [],
      "source": [
        "def calculate_entropy(list_values):\n",
        "\tcounter_values = Counter(list_values).most_common()\n",
        "\tprobabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
        "\tentropy=scipy.stats.entropy(probabilities)\n",
        "\treturn entropy\n",
        "\n",
        "def calculate_statistics(list_values):\n",
        "\tn5 = np.nanpercentile(list_values, 5)\n",
        "\tn25 = np.nanpercentile(list_values, 25)\n",
        "\tn75 = np.nanpercentile(list_values, 75)\n",
        "\tn95 = np.nanpercentile(list_values, 95)\n",
        "\tmedian = np.nanpercentile(list_values, 50)\n",
        "\tmean = np.nanmean(list_values)\n",
        "\tstd = np.nanstd(list_values)\n",
        "\tvar = np.nanvar(list_values)\n",
        "\trms = np.nanmean(np.sqrt(list_values**2))\n",
        "\treturn [n5, n25, n75, n95, median, mean, std, var, rms]\n",
        "\n",
        "def calculate_crossings(list_values):\n",
        "\tzero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
        "\tno_zero_crossings = len(zero_crossing_indices)\n",
        "\tmean_crossing_indices = np.nonzero(np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
        "\tno_mean_crossings = len(mean_crossing_indices)\n",
        "\treturn [no_zero_crossings, no_mean_crossings]\n",
        "\n",
        "def get_features(list_values):\n",
        "\tentropy = calculate_entropy(list_values)\n",
        "\tcrossings = calculate_crossings(list_values)\n",
        "\tstatistics = calculate_statistics(list_values)\n",
        "\treturn [entropy] + crossings + statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ci6GgZF38Mv"
      },
      "source": [
        "## Given an audio file returns the corresponding wavelet features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4Vtf7XXP38Mv"
      },
      "outputs": [],
      "source": [
        "def extract_dtcwt(file_path:str):\n",
        "    d, fs = librosa.load(file_path)\n",
        "    forw = trans.forward(d, nlevels=17)\n",
        "    features = []\n",
        "    for coeff in forw.highpasses:\n",
        "        temp = (np.abs(coeff.squeeze()))\n",
        "        features += get_features(temp)\n",
        "\n",
        "    features += get_features(forw.lowpass.squeeze())\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DcbsiVBf38Mv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "data_path = '/content/drive/MyDrive/GTZAN/Ensemble_Data/audios/models/'\n",
        "\n",
        "genres = ['blues', 'classical', 'country', 'disco',\n",
        "          'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "def index_genre(genre, genres):\n",
        "    for (g,index) in zip(genres, range(len(genres))):\n",
        "        if(g == genre):\n",
        "            return index\n",
        "    return -1\n",
        "\n",
        "def get_data(data_path, genres, decoder, training_percentaje=0.6, validation_percentaje=0.2, test_percentaje=0.2):\n",
        "    \"\"\"\n",
        "    data_path: se le pasa la direccion de la carpeta donde se encuentra la base de datos.\n",
        "    genres: se le pasa una lista con los nombres da cada carpeta que contiene un genero dado.\n",
        "    decoder: funcion para decodificar el dato que se le pasa, por ejemplo en caso de imagenes habria hacer imread\n",
        "    \"\"\"\n",
        "\n",
        "    data_training = {'in': [], 'out': []}\n",
        "    data_validation = {'in': [], 'out': []}\n",
        "    data_test = {'in': [], 'out': []}\n",
        "\n",
        "    for genre in genres:\n",
        "        files = os.listdir(data_path + genre)\n",
        "        count = len(files)\n",
        "\n",
        "        for (filename, index) in zip(files, range(len(files))):\n",
        "            filepath = data_path + genre + '/' + filename\n",
        "\n",
        "            if (index < training_percentaje * count):\n",
        "                data_training['in'].append(decoder(filepath))\n",
        "                data_training['out'].append(index_genre(genre, genres))\n",
        "                continue\n",
        "\n",
        "            if (index < (training_percentaje + validation_percentaje) * count):\n",
        "                data_validation['in'].append(decoder(filepath))\n",
        "                data_validation['out'].append(index_genre(genre, genres))\n",
        "            else:\n",
        "                data_test['in'].append(decoder(filepath))\n",
        "                data_test['out'].append(index_genre(genre, genres))\n",
        "\n",
        "    data_training = {'in': np.array(data_training['in']),'out': np.array(data_training['out'])}\n",
        "    data_validation = {'in': np.array(data_validation['in']),'out': np.array(data_validation['out'])}\n",
        "    data_test = {'in': np.array(data_test['in']),'out': np.array(data_test['out'])}\n",
        "\n",
        "    return {\n",
        "        'data_training': data_training,\n",
        "        'data_validation': data_validation,\n",
        "        'data_testing': data_test\n",
        "    }\n",
        "\n",
        "def get_data_wavelet(training_percentaje=0.8, validation_percentaje=0.1, test_percentaje=0.1):\n",
        "    return get_data(data_path, genres, extract_dtcwt, training_percentaje,validation_percentaje,test_percentaje)\n",
        "\n",
        "wavalet_data = get_data_wavelet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWncKx5d38Mw"
      },
      "source": [
        "### If you want the features for the whole dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "fYDJ9NyQ38Mx",
        "outputId": "c4031773-b386-4026-efec-b6a765a4a8dd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-41f2da88f5a9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgenre\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGENRES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'dataset/genres/{genre}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mmatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"(\\w+).(\\d+).wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/genres/blues'"
          ]
        }
      ],
      "source": [
        "x_features = []\n",
        "y  = []\n",
        "for genre in GENRES:\n",
        "    for wav in os.listdir(f'dataset/genres/{genre}'):\n",
        "        matched = re.match(r\"(\\w+).(\\d+).wav\", wav)\n",
        "        if matched:\n",
        "            features = extract_dtcwt(f'dataset/genres/{genre}/{wav}')\n",
        "\n",
        "            y.append(genre)\n",
        "            x_features.append(features)\n",
        "\n",
        "x_features = np.array(x_features)\n",
        "y = np.array(y)\n",
        "np.save('dtcwt/dtcwt_15_lvl17', x_features)\n",
        "np.save('dtcwt/dtcwt_y', y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1k3sZZ38My"
      },
      "outputs": [],
      "source": [
        "X_dtcwt = np.load('dtcwt/dtcwt_15_lvl17.npy')\n",
        "y = np.load('dtcwt/dtcwt_y.npy')\n",
        "X_dtcwt.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmvfAg1t38My"
      },
      "source": [
        "Get a random scaled, train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oSiIlVXC38My"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "def encoder_scaler(X_dtcwt, y):\n",
        "    encoder = LabelEncoder()\n",
        "    y = encoder.fit_transform(y)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_dtcwt_scaled = scaler.fit_transform(X_dtcwt)\n",
        "    X_dtcwt_train_f, X_dtcwt_test_f, y_dtcwt_train_f, y_dtcwt_test_f = train_test_split(X_dtcwt_scaled, y, test_size = 0.2,random_state=42)\n",
        "    return X_dtcwt_train_f, X_dtcwt_test_f, y_dtcwt_train_f, y_dtcwt_test_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yfsaYAB38My",
        "outputId": "ad66ec3a-f1cd-4c89-ce1c-0ef1dd94ca7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.56\n"
          ]
        }
      ],
      "source": [
        "# X_dtcwt = np.load('dtcwt/dtcwt_15_lvl17.npy')\n",
        "# y = np.load('dtcwt/dtcwt_y.npy')\n",
        "# retrain model\n",
        "# X_dtcwt_train_f, X_dtcwt_test_f, y_dtcwt_train_f, y_dtcwt_test_f = encoder_scaler(X_dtcwt, y)\n",
        "\n",
        "dtcwt_rf = RandomForestClassifier(n_estimators=100,max_depth=13,bootstrap=False,random_state=42)\n",
        "\n",
        "#region new changes\n",
        "X_dtcwt_train_f = wavalet_data['data_training']['in']\n",
        "y_dtcwt_train_f = wavalet_data['data_training']['out']\n",
        "X_dtcwt_test_f =  wavalet_data['data_testing']['in']\n",
        "y_dtcwt_test_f =  wavalet_data['data_testing']['out']\n",
        "#endregion\n",
        "\n",
        "dtcwt_rf.fit(X_dtcwt_train_f,y_dtcwt_train_f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Ensemble/dtcwt_rf.bin','wb') as mod:\n",
        "    pickle.dump(dtcwt_rf,mod)\n",
        "# https://scikit-learn.org/stable/model_persistence.html\n",
        "\n",
        "print(dtcwt_rf.score(X_dtcwt_test_f, y_dtcwt_test_f))\n",
        "ypred_dtcwt_rf = dtcwt_rf.predict(X_dtcwt_test_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS34kt0Y38Mz"
      },
      "source": [
        "Plot a confusion matrix to corroborate the behavior of the model for each genre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0S5kV8j38Mz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# create confusion matrix\n",
        "cm = confusion_matrix(y_dtcwt_test_f, ypred_dtcwt_rf)\n",
        "\n",
        "accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "misclass = 1 - accuracy\n",
        "\n",
        "cmap = plt.get_cmap('Blues')\n",
        "\n",
        "# plot confusion matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "plt.title('Confusion matrix DTCWT Random Forest')\n",
        "plt.colorbar()\n",
        "\n",
        "tick_marks = np.arange(len(GENRES))\n",
        "plt.xticks(tick_marks, GENRES, rotation=45)\n",
        "plt.yticks(tick_marks, GENRES)\n",
        "\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > (cm.max() / 2) else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "plt.savefig('ConfM_DTCWT_rf.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orGMA68s38Mz"
      },
      "source": [
        "A Cross-Validation using K-Fold to validate the accuracy in the previous fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGBFdrYW38Mz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "kfold=KFold(n_splits=5 , shuffle=True,random_state=0)\n",
        "rf_scores = cross_val_score(dtcwt_rf, X_dtcwt, y, cv=kfold)\n",
        "\n",
        "print('scores: ',rf_scores) # [0.735      0.705      0.8        0.81       0.79396985]\n",
        "print('mean: ',rf_scores.mean()) # 0.7687939698492463\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Cross-Validation Scores in Random Forest for DTCWT')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Score')\n",
        "ax = plt.gca()\n",
        "ax.set_xlim(0.9, 5.1)\n",
        "ax.set_ylim(0.6, 1.01)\n",
        "plt.grid()\n",
        "plt.plot(range(1,6),rf_scores,'o-',color='blue',lw=2)\n",
        "plt.plot(range(1,6),[rf_scores.mean()]*5, linestyle=\"-.\",color='k')\n",
        "plt.annotate(\"%0.4f\" % rf_scores.mean(), (3,rf_scores.mean() + 0.005))\n",
        "plt.legend(['accuracy','mean acc'],loc=\"best\")\n",
        "plt.savefig('CV_DTCWT_rf.png')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}