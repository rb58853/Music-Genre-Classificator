{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PauOcS3sfRZk",
        "outputId": "a4e89ddc-791a-4382-b325-b464f698c469"
      },
      "outputs": [],
      "source": [
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2vxgDeJ0MVY",
        "outputId": "56bef2ac-672e-4be7-bf8c-b23e2ddbb17a"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W8iTuG8GfRZo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "data: dict\n",
        "epochs_ = 300\n",
        "lr = 0.001\n",
        "kernel = (2,2)\n",
        "size_images = (192, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NOA88stDfRZp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def index_genre(genre, genres):\n",
        "    for (g,index) in zip(genres, range(len(genres))):\n",
        "        if(g == genre):\n",
        "            return index\n",
        "    raise Exception(f\"Not found the {genre}\")\n",
        "\n",
        "def get_data_from_path(data_path,genres, decoder):\n",
        "    data = {'in': [], 'out': []}\n",
        "    for genre in genres:\n",
        "        files = os.listdir(data_path + genre)\n",
        "        for filename in files:\n",
        "            filepath = data_path + genre + '/' + filename\n",
        "            data['in'].append(decoder(filepath))\n",
        "            data['out'].append(index_genre(genre, genres))\n",
        "\n",
        "    data = {'in': np.array(data['in']),'out': np.array(data['out'])}\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R77H5JCvfRZs"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def read_image(filepath):\n",
        "    global size_images\n",
        "    image = cv2.imread(filepath)\n",
        "    return cv2.resize(image, size_images)\n",
        "\n",
        "genres = ['blues', 'classical', 'country', 'disco',\n",
        "          'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "data_path_train = 'path_train'\n",
        "data_path_test = 'path_test'\n",
        "data_path_validation = 'path_validation'\n",
        "\n",
        "def get_data_train_mfcc():\n",
        "    return get_data_from_path(data_path_train, genres, read_image)\n",
        "def get_data_test_mfcc():\n",
        "    return get_data_from_path(data_path_test, genres, read_image)\n",
        "def get_data_validation_mfcc():\n",
        "    return get_data_from_path(data_path_validation, genres, read_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ogMq2ce7fRZv"
      },
      "outputs": [],
      "source": [
        "def training():\n",
        "    global epochs_\n",
        "    global size_images\n",
        "    global lr\n",
        "\n",
        "    training_data = get_data_train_mfcc\n",
        "    v_data = get_data_validation_mfcc\n",
        "\n",
        "    model = mfcc_cnn_model(input_shape=(\n",
        "        size_images[1], size_images[0], 3), classes=10, filter_shape=kernel)\n",
        "\n",
        "    model.compile(\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        '/content/drive/MyDrive/mfcc_models/best_weights.h5',\n",
        "        save_weights_only=True,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    model.fit(\n",
        "        training_data['in'], training_data['out'],\n",
        "        validation_data=(v_data['in'], v_data['out']),\n",
        "        epochs=epochs_,\n",
        "        callbacks=[checkpoint]\n",
        "        )\n",
        "\n",
        "    model.save('/content/drive/MyDrive/mfcc_models/mfcc_model.h5')\n",
        "\n",
        "def testing(model_name=\"mfcc_model.h5\", epoch_name = 'best_weights.h5'):\n",
        "    global data\n",
        "    global size_images\n",
        "\n",
        "    data = get_data_test_mfcc()\n",
        "    input = data['in']\n",
        "    output = data['out']\n",
        "\n",
        "    path = '/content/drive/MyDrive/mfcc_models/' + model_name\n",
        "    path_best_epoch = '/content/drive/MyDrive/mfcc_models/' + epoch_name\n",
        "\n",
        "    model = keras.models.load_model(path)\n",
        "\n",
        "    score = model.evaluate(input, output, verbose=0)\n",
        "    # print('testing loss: ' + str(score[0]))\n",
        "    print('testing accuracy: ' + str(score[1]))\n",
        "\n",
        "    input = data['data_validation']['in']\n",
        "    output = data['data_validation']['out']\n",
        "    score = model.evaluate(input, output, verbose=0)\n",
        "    # print('validation loss: ' + str(score[0]))\n",
        "    print('validation accuracy: ' + str(score[1]))\n",
        "\n",
        "    input = data['data_training']['in']\n",
        "    output = data['data_training']['out']\n",
        "    score = model.evaluate(input, output, verbose=0)\n",
        "    # print('training loss: ' + str(score[0]))\n",
        "    print('training accuracy: ' + str(score[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uCHuoORLfRZx"
      },
      "outputs": [],
      "source": [
        "def mfcc_cnn_model(input_shape=(128, 96, 1), classes=10, filter_shape=(3, 3)):\n",
        "    X_input = keras.layers.Input(input_shape)\n",
        "\n",
        "    X = keras.layers.Conv2D(32, filter_shape, activation='relu')(X_input)\n",
        "\n",
        "    X = keras.layers.Conv2D(64, filter_shape, activation='relu')(X)\n",
        "    X = keras.layers.AveragePooling2D((2, 2))(X)\n",
        "\n",
        "    X = keras.layers.Conv2D(128, filter_shape, activation='relu')(X)\n",
        "    X = keras.layers.AveragePooling2D((2, 2))(X)\n",
        "\n",
        "    X = keras.layers.Conv2D(256, filter_shape, activation='relu')(X)\n",
        "    X = keras.layers.GlobalAveragePooling2D()(X)\n",
        "\n",
        "    X = keras.layers.Dense(256, activation='relu')(X)\n",
        "    X = keras.layers.Dense(128, activation='relu')(X)\n",
        "    X = keras.layers.Dense(64, activation='relu')(X)\n",
        "    X = keras.layers.Dense(32, activation='relu')(X)\n",
        "    X = keras.layers.Dense(classes, activation='softmax')(X)\n",
        "\n",
        "    return keras.models.Model(inputs=X_input, outputs=X, name='SpectrogramCNN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1_3ChDmfRZy",
        "outputId": "280ff39f-ee1f-4576-ffdb-522a3c5a83e7"
      },
      "outputs": [],
      "source": [
        "training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Iz-4TrvzXAVs"
      },
      "outputs": [],
      "source": [
        "#Save Weights in Model\n",
        "def save_model(model_name=\"mfcc_model.h5\", epoch_name = 'best_weights.h5'):\n",
        "    path = '/content/drive/MyDrive/mfcc_models/' + model_name\n",
        "    path_best_epoch = '/content/drive/MyDrive/mfcc_models/' + epoch_name\n",
        "    model = keras.models.load_model(path)\n",
        "    model.load_weights(path_best_epoch)\n",
        "    model.save('/content/drive/MyDrive/mfcc_models/mfcc_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iyZvYv3fRZy",
        "outputId": "b8b699fb-a2f0-4953-ead1-3b72f2b5b561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing accuracy: 0.7986577153205872\n",
            "validation accuracy: 0.7266666889190674\n",
            "training accuracy: 0.9527220726013184\n"
          ]
        }
      ],
      "source": [
        "save_model()\n",
        "testing()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
